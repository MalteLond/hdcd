% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/hdcd.R
\name{hdcd}
\alias{hdcd}
\title{hdcd}
\usage{
hdcd(x, delta = 0.1, lambda = NULL, lambda_min_ratio = 0.01,
  lambda_grid_size = 10, gamma = NULL, method = c("nodewise_regression",
  "summed_regression", "ratio_regression"), penalize_diagonal = F,
  optimizer = c("line_search", "ternary_search", "section_search"),
  control = NULL, standardize = T, threshold = 1e-07, n_folds = 10,
  verbose = T, parallel = T, ...)
}
\arguments{
\item{x}{A n times p matrix or data frame.}

\item{delta}{Numeric value between 0 and 0.5. This tuning parameter determines
the minimal segment size proportional to the size of the dataset and hence
an upper bound for the number of changepoints (roughly \eqn{1/\delta}).}

\item{lambda}{Positive numeric value. This is the regularization parameter in
the single Lasso fits.}

\item{lambda_min_ratio}{Numeric value between 0 and 1. If the \eqn{\lambda_max} is determined internally this will pick \eqn{\lambda_min = lambda_min_ratio * \lambda_max}.}

\item{lambda_grid_size}{Integer value determining the number of values between \eqn{\lambda_min} and \eqn{\lambda_max} to will be equally spaced on a logarithmic scale.}

\item{gamma}{Numeric value or vector. If NULL the full solution path for gamma will be caluclated for every combination of \eqn{\lambda} and \eqn{\delta}}

\item{method}{Which estimator should be used? Possible choices are \itemize{
\item \strong{nodewise_regression}: Nodewise regression is based on a single
node that needs to be specified with an additional parameter \code{node}
pointing to the column index of the node of interest. Uses \code{\link[glmnet]{glmnet}} internally. See Kovács (2016) for details.
\item \strong{summed_regression}: Summed nodewise regression sums up the residual
variances of nodewise regression over all nodes. Uses \code{\link[glasso]{glasso}} internally. See Kovács (2016)  for details.
\item \strong{ratio_regression}: Likelihood ratio based regression sums the
pseudo-profile-likelihood over all nodes. Uses \code{\link[glasso]{glasso}} internally. See Kovács (2016)  for details.
\item \strong{glasso}: The graphical Lasso uses the approach of Friedman et al (2007).
In contrast to the other approaches the exact likelihood the whole graphical
model is computed and used as loss. }}

\item{penalize_diagonal}{Boolean, should the diagonal elements of the
precision matrix be penalized by \eqn{\lambda}?}

\item{optimizer}{Which search technique should be used for performing
individual splits in the binary segmentation alogrithm? Possible choices are
\itemize{
\item \strong{line_search}: Exhaustive linear search. All possivle split candidates are
evaluated and the index with maximal loss reduction is returned.
\item \strong{ternary_search}: Iteratively
cuts the search space by a fixed ratio and approximately finds an index at a
local maximum. See Haubner (2018) for details.
\item \strong{section_search}: Iteratively cuts the search space
according by a flexible ratio as determined by parameter \code{stepsize} in \code{control} parameter list
and approximately finds an index at a local maximum. See Haubner (2018) for details. }}

\item{control}{A list with parameters that is accessed by the selected optimizer:
\itemize{ \item \strong{stepsize}: Numeric value between 0 and 0.5. Used by section
search. \item \strong{intervals}: Integer value larger than 3. Used by ternary
search.}}

\item{standardize}{Boolean. If TRUE the penalty parameter \eqn{\lambda} will
be adjusted for every dimension in the single Lasso fits according to the standard deviation in the data.}

\item{threshold}{The threshold for halting the iteration in \code{\link[glasso]{glasso}} or \code{\link[glmnet]{glmnet}}.
In the former it controls the absolute change of single parameters in the
latter it controls the total objective value.}

\item{n_folds}{Number of folds. Test data will be selected equi-spaced, i.e. each n_fold-th observation.}

\item{verbose}{Boolean. If TRUE additional information will be printed.}

\item{parallel}{If TRUE and a parallel backend is registered, the cross-validation will be performed in parallel.}

\item{...}{Supply additional arguments for a specific method (e.g. \code{node} for
\strong{nodewise_regression})}
}
\value{
For a single fit a list with elements

\describe{
  \item{changepoints}{A numeric list with the indices of the changepoints}
  \item{tree}{The fully grown binary tree}
}

For cross-validation a list with elements

#' \describe{
  \item{changepoints}{A numeric list with the indices of the changepoints}
  \item{cv_results}{A multi-dimensional array with the cross-validation results}
  \item{cv_gamma}{Best gamma value}
  \item{cv_lambda}{Best lambda value}
  \item{cv_delta}{Best delta value}
}

If only a single fit was performed a list with the found changepoints as well as the fully grown binary tree are returned. For cross-validation the a list with the found changepopints, the optimal parameter values and the full results is returned.
}
\description{
High Dimensional Changepoint Detection
}
\examples{
dat <- SimulateFromModel(CreateModel(n_segments = 2,n = 100,p = 30, ChainNetwork))
\dontrun{
hdcd(dat, 0.1, 0.1, 0.05, method = "summed_regression", verbose = T)
}
}
